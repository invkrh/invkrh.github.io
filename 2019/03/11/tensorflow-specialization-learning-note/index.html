<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">










  <meta name="google-site-verification" content="jR_bUEN846roQfh9C1VWdQ9eb9YaT7E_G142mMBeqow">












  
  
  
  

  
    
    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link rel="stylesheet" referrerpolicy="no-referrer" type="text/css" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Lato:300,300italic,400,400italic,700,700italic|Raleway:300,300italic,400,400italic,700,700italic|Parisienne:300,300italic,400,400italic,700,700italic|Consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png?v=7.1.0">


  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="A learning note of the coursera specialization TensorFlow: From Basics to Mastery given by deeplearning.ai.  Course 1: Introduction to TensorFlow for AI, ML and DL Course 2: Convolutional Neural Netwo">
<meta name="keywords" content="Coding,TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow Specialization Learning Note">
<meta property="og:url" content="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/index.html">
<meta property="og:site_name" content="Yorozuya">
<meta property="og:description" content="A learning note of the coursera specialization TensorFlow: From Basics to Mastery given by deeplearning.ai.  Course 1: Introduction to TensorFlow for AI, ML and DL Course 2: Convolutional Neural Netwo">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/shoes.png">
<meta property="og:image" content="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/horse-vs-human.jpeg">
<meta property="og:updated_time" content="2019-05-07T19:56:06.056Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow Specialization Learning Note">
<meta name="twitter:description" content="A learning note of the coursera specialization TensorFlow: From Basics to Mastery given by deeplearning.ai.  Course 1: Introduction to TensorFlow for AI, ML and DL Course 2: Convolutional Neural Netwo">
<meta name="twitter:image" content="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/shoes.png">



  <link rel="alternate" href="/atom.xml" title="Yorozuya" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Tensorflow Specialization Learning Note | Yorozuya</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-74632317-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-74632317-1');
    }
  </script>









  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


  <link rel="stylesheet" href="/css/prism.css">
  <link rel="stylesheet" href="/css/mathjax-md.css">
</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yorozuya</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hao Ren">
      <meta itemprop="description" content="Machine Learning Engineer @ Criteo">
      <meta itemprop="image" content="/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yorozuya">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tensorflow Specialization Learning Note

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-03-11 23:03:33" itemprop="dateCreated datePublished" datetime="2019-03-11T23:03:33+01:00">2019-03-11</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">Comments: </span>
                <a href="/2019/03/11/tensorflow-specialization-learning-note/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/11/tensorflow-specialization-learning-note/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>A learning note of the coursera specialization <strong><a href="https://www.deeplearning.ai/tensorflow-specialization/" target="_blank" rel="noopener">TensorFlow: From Basics to Mastery</a></strong> given by <a href="http://deeplearning.ai" target="_blank" rel="noopener">deeplearning.ai</a>.</p>
<ul>
<li>Course 1: Introduction to TensorFlow for AI, ML and DL</li>
<li>Course 2: Convolutional Neural Networks in TensorFlow</li>
<li>Coming soon …</li>
</ul>
<a id="more"></a>
<h1 id="C1W1-A-New-Programming-Paradigm"><a href="#C1W1-A-New-Programming-Paradigm" class="headerlink" title="C1W1: A New Programming Paradigm"></a>C1W1: A New Programming Paradigm</h1><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><h3 id="New-programming-paradigm"><a href="#New-programming-paradigm" class="headerlink" title="New programming paradigm"></a>New programming paradigm</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>input</th>
<th>output</th>
</tr>
</thead>
<tbody>
<tr>
<td>Triditional Programming</td>
<td>Rules, Data</td>
<td>Answers</td>
</tr>
<tr>
<td>Machine Learning</td>
<td>Answers, Data</td>
<td>Rules</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="How-to-fit-a-line"><a href="#How-to-fit-a-line" class="headerlink" title="How to fit a line"></a>How to fit a line</h3><pre><code class="lang-python">import tensorflow as tf
import numpy as np
from tensorflow import keras
model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mean_squared_error&#39;)
xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)
model.fit(xs, ys, epochs=500)
print(model.predict([10.0]))
</code></pre>
<p>The predicted value is not 19.0 but a little under. It is because neural networks deal with probabilities, so given the data that we fed the NN with, it calculated that there is a very high probability that the relationship between $X$ and $Y$ is $Y=2X-1$, but with only 6 data points we can’t know for sure. As a result, the result for 10 is very close to 19, but not necessarily 19.</p>
<hr>
<h1 id="C1W2-Introduction-to-Computer-Vision"><a href="#C1W2-Introduction-to-Computer-Vision" class="headerlink" title="C1W2: Introduction to Computer Vision"></a>C1W2: Introduction to Computer Vision</h1><h2 id="Note-1"><a href="#Note-1" class="headerlink" title="Note"></a>Note</h2><h3 id="Why-are-the-labels-numbers-instead-of-words"><a href="#Why-are-the-labels-numbers-instead-of-words" class="headerlink" title="Why are the labels numbers instead of words"></a>Why are the labels numbers instead of words</h3><p>Using a number is a first step in avoiding bias — instead of labelling it with words in a specific language and excluding people who don’t speak that language! You can learn more about bias and techniques to avoid it <a href="https://developers.google.com/machine-learning/fairness-overview/" target="_blank" rel="noopener">here</a>.</p>
<h3 id="What-is-cross-entropy-CE"><a href="#What-is-cross-entropy-CE" class="headerlink" title="What is cross entropy (CE)"></a>What is cross entropy (CE)</h3><script type="math/tex; mode=display">CE = - \sum_{i=0}^{C - 1} y_i \cdot log( f(\vec{x_i}) )</script><p>where </p>
<ul>
<li>$C$: the number of classes</li>
<li>$\vec{x_i}$: the feature vector of the example $i$</li>
<li>$y_i$: the label of the example $i$</li>
<li>$f$: the learned prediction function which takes the feacture vector $\vec{x_i}$ and returns the probability of being class $y_i$</li>
</ul>
<p>When $c = 2$</p>
<script type="math/tex; mode=display">CE = - \big[ y_i \cdot log( p_i ) + (1 - y_i) \cdot log( 1 - p_i ) \big]</script><h3 id="Difference-between-categorical-crossentropy-and-sparse-categorical-crossentropy"><a href="#Difference-between-categorical-crossentropy-and-sparse-categorical-crossentropy" class="headerlink" title="Difference between categorical_crossentropy and sparse_categorical_crossentropy"></a>Difference between <code>categorical_crossentropy</code> and <code>sparse_categorical_crossentropy</code></h3><ul>
<li>If your targets are one-hot encoded, use categorical_crossentropy.<br>Examples of one-hot encodings:<pre><code>[1,0,0]
[0,1,0]
[0,0,1]
</code></pre></li>
<li>But if your targets are integers, use sparse_categorical_crossentropy.<br>Examples of integer encodings (for the sake of completion):<pre><code>1
2
3
</code></pre></li>
</ul>
<h2 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h2><pre><code class="lang-python"># Early stopping
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get(&#39;loss&#39;)&lt;0.4):
      print(&quot;\nReached 60% accuracy so cancelling training!&quot;)
      self.model.stop_training = True

callbacks = myCallback()

mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
# Data normalization
training_images  = training_images / 255.0
test_images = test_images / 255.0
model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), 
                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), 
                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])
model.compile(optimizer = &#39;adam&#39;,
              loss = &#39;sparse_categorical_crossentropy&#39;,
              metrics=[&#39;accuracy&#39;])
model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])
model.evaluate(test_images, test_labels)
</code></pre>
<hr>
<h1 id="C1W3-Enhancing-Vision-with-Convolutional-Neural-Networks"><a href="#C1W3-Enhancing-Vision-with-Convolutional-Neural-Networks" class="headerlink" title="C1W3: Enhancing Vision with Convolutional Neural Networks"></a>C1W3: Enhancing Vision with Convolutional Neural Networks</h1><h2 id="Note-2"><a href="#Note-2" class="headerlink" title="Note"></a>Note</h2><h3 id="Convolution-Layer"><a href="#Convolution-Layer" class="headerlink" title="Convolution Layer"></a>Convolution Layer</h3><p>Each kernal is an edge detector which is perfect for computer vision, because often it’s features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less…because you’ll just train on the highlighted features.</p>
<h3 id="MaxPooling-Layer"><a href="#MaxPooling-Layer" class="headerlink" title="MaxPooling Layer"></a>MaxPooling Layer</h3><p>The convolution layer is followed by a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convolution</p>
<h3 id="Why-CNN-works"><a href="#Why-CNN-works" class="headerlink" title="Why CNN works"></a>Why CNN works</h3><p>CNN tries different filters on the image and learning which ones work when looking at the training data. As a result, when it works, you’ll have greatly reduced information passing through the network, but because it isolates and identifies features, you can also get increased accuracy</p>
<h2 id="Code-2"><a href="#Code-2" class="headerlink" title="Code"></a>Code</h2><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><pre><code class="lang-Python"># Reshape to a 4D tensor, otherwise the Convolutions do not recognize the shape
training_images=training_images.reshape(60000, 28, 28, 1)
training_images=training_images / 255.0
test_images = test_images.reshape(10000, 28, 28, 1)
test_images=test_images/255.0

# 2-convolution-layer NN
model = tf.keras.models.Sequential([
  # default: strides = 1, padding = &#39;valid&#39;
  tf.keras.layers.Conv2D(64, (3,3), activation=&#39;relu&#39;, input_shape=(28, 28, 1)), 
  # default: strides = None (same as pool_size), padding = &#39;valid&#39;
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation=&#39;relu&#39;), 
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation=&#39;relu&#39;),
  tf.keras.layers.Dense(10, activation=&#39;softmax&#39;)
])
</code></pre>
<pre><code>_________________________________________________________________ || 
Layer (type)                 Output Shape              Param #    || Comments
================================================================= || 
conv2d (Conv2D)              (None, 26, 26, 64)        640        || = 64 x (3 x 3 x 1 + 1)
_________________________________________________________________ || 
max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0          || 
_________________________________________________________________ || 
conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928      || = 64 x (3 x 3 x 64 + 1)
_________________________________________________________________ || 
max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0          || 
_________________________________________________________________ || 
flatten_1 (Flatten)          (None, 1600)              0          || 
_________________________________________________________________ || 
dense_2 (Dense)              (None, 128)               204928     || = 128 x (1600 + 1)
_________________________________________________________________ || 
dense_3 (Dense)              (None, 10)                1290       || = 10 * (128 + 1)
================================================================= || 
Total params: 243,786
Trainable params: 243,786
Non-trainable params: 0
</code></pre><h3 id="How-to-compute-output-size"><a href="#How-to-compute-output-size" class="headerlink" title="How to compute output size"></a>How to compute output size</h3><p>Convolution layer</p>
<script type="math/tex; mode=display">(n + 2p - f + 1) \times (n + 2p - f + 1)</script><p>MaxPooling layer</p>
<script type="math/tex; mode=display">Floor(\frac{height - f}{s} + 1) \times Floor(\frac{weight - f}{s} + 1)</script><ul>
<li>$n$: input size</li>
<li>$p$: padding size</li>
<li>$f$: filter size</li>
</ul>
<h3 id="Two-kinds-of-padding"><a href="#Two-kinds-of-padding" class="headerlink" title="Two kinds of padding:"></a>Two kinds of padding:</h3><ul>
<li>Valid: no padding<script type="math/tex; mode=display">p = 0</script></li>
<li>Same: results in padding the input such that the output has the same length as the original input<script type="math/tex; mode=display">n + 2p - f + 1 = n \implies p = (f - 1) / 2</script>where $f$ is almost always odd number</li>
</ul>
<h3 id="How-to-compute-number-of-parameters"><a href="#How-to-compute-number-of-parameters" class="headerlink" title="How to compute number of parameters"></a>How to compute number of parameters</h3><script type="math/tex; mode=display">NF \times (f \times f \times NC_{input} + 1 )</script><ul>
<li>$NF$: number of filters</li>
<li>$NC_{input}$: number of input channels</li>
<li>Each filter has a bias term</li>
<li><a href="https://www.youtube.com/watch?v=KTB_OFoAQcc" target="_blank" rel="noopener">Convolutions Over Volume</a></li>
</ul>
<h3 id="Visualizing-the-Convolutions-and-Pooling"><a href="#Visualizing-the-Convolutions-and-Pooling" class="headerlink" title="Visualizing the Convolutions and Pooling"></a>Visualizing the Convolutions and Pooling</h3><img src="/2019/03/11/tensorflow-specialization-learning-note/shoes.png" title="Layer outputs">
<p>Each row represents an itea. There are 3 shoes images here.<br>The 4 columns represent the output of the first 4 layers (conv2d, max_pooling2d, conv2d_1, max_pooling2d_1).<br>We can find the commonality for the same kind of items.</p>
<hr>
<h1 id="C1W4-Using-Real-world-Images"><a href="#C1W4-Using-Real-world-Images" class="headerlink" title="C1W4: Using Real-world Images"></a>C1W4: Using Real-world Images</h1><h2 id="Note-3"><a href="#Note-3" class="headerlink" title="Note"></a>Note</h2><h3 id="ImageGenerator"><a href="#ImageGenerator" class="headerlink" title="ImageGenerator"></a>ImageGenerator</h3><ul>
<li>ImageGenerator can flow images from a directory and perform operations such as resizing them on the fly. </li>
<li>You can point it at a directory and then the <strong>sub-directories</strong> of that will automatically generate labels for you</li>
</ul>
<pre><code>images
|-- training
|   |-- horse
|   |   |-- 1.jpg
|   |   |-- 2.jpg
|   |   `-- 3.jpg
|   `-- human
|       |-- 1.jpg
|       |-- 2.jpg
|       `-- 3.jpg
`-- validation
    |-- horse
    |   |-- 1.jpg
    |   |-- 2.jpg
    |   `-- 3.jpg
    `-- human
        |-- 1.jpg
        |-- 2.jpg
        `-- 3.jpg
</code></pre><p>If you point <code>ImageGenerator</code> to <strong>training</strong> directory, it will generate a stream of images labelled with horse or human</p>
<h3 id="Mini-batch"><a href="#Mini-batch" class="headerlink" title="Mini-batch"></a>Mini-batch</h3><h4 id="Why-mini-batch"><a href="#Why-mini-batch" class="headerlink" title="Why mini-batch"></a>Why mini-batch</h4><p>For large neural networks with very large and highly redundant training sets, it is nearly always best to use mini-batch learning.</p>
<ul>
<li>The mini-batches may need to be quite big when adapting fancy methods.</li>
<li>Big mini-batches are more computationally efficient.</li>
</ul>
<h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><ul>
<li>Momentum</li>
<li>RMSProp</li>
<li>Adam</li>
</ul>
<h2 id="Code-3"><a href="#Code-3" class="headerlink" title="Code"></a>Code</h2><h3 id="Model-1"><a href="#Model-1" class="headerlink" title="Model"></a>Model</h3><pre><code class="lang-python">import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 300x300 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(16, (3,3), activation=&#39;relu&#39;, input_shape=(300, 300, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fifth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation=&#39;relu&#39;),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (&#39;horses&#39;) and 1 for the other (&#39;humans&#39;)
    tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;)
])

# Train our model with the binary_crossentropy loss, 
# because it&#39;s a binary classification problem and our final activation is a sigmoid.
# [More details](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
model.compile(loss=&#39;binary_crossentropy&#39;,
              optimizer=RMSprop(lr=0.001),
              metrics=[&#39;acc&#39;])

model.summary()
</code></pre>
<pre><code>Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 298, 298, 16)      448       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense (Dense)                (None, 512)               1606144   
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 1,704,097
Trainable params: 1,704,097
Non-trainable params: 0
</code></pre><blockquote>
<p>The convolutions reduce the shape from 90000 (300 x 300) down to 3136</p>
</blockquote>
<h3 id="ImageDataGenerator"><a href="#ImageDataGenerator" class="headerlink" title="ImageDataGenerator"></a>ImageDataGenerator</h3><pre><code class="lang-python"># All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)
validation_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        &#39;/tmp/horse-or-human/&#39;,  # This is the source directory for training images
        target_size=(300, 300),  # All images will be resized to 150x150
        batch_size=128, # number of images for each batch
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode=&#39;binary&#39;)

# Flow training images in batches of 128 using train_datagen generator
validation_generator = validation_datagen.flow_from_directory(
        &#39;/tmp/validation-horse-or-human/&#39;,  # This is the source directory for validation images
        target_size=(300, 300),  # All images will be resized to 150x150
        batch_size=32, # number of images for each batch
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode=&#39;binary&#39;)

history = model.fit_generator(
      train_generator,
      steps_per_epoch=8, # number of batches for each epoch durning training  
      epochs=15,
      verbose=1,
      validation_data = validation_generator,
      validation_steps=8) # number of batches for each epoch durning validation
</code></pre>
<h3 id="Visualizing-Intermediate-Representations"><a href="#Visualizing-Intermediate-Representations" class="headerlink" title="Visualizing Intermediate Representations"></a>Visualizing Intermediate Representations</h3><img src="/2019/03/11/tensorflow-specialization-learning-note/horse-vs-human.jpeg" title="Intermediate outputs">
<p>As you can see we go from the raw pixels of the images to increasingly abstract and compact representations. The representations downstream start highlighting what the network pays attention to, and they show fewer and fewer features being “activated”; most are set to zero. This is called “sparsity.” Representation sparsity is a key feature of deep learning.</p>
<p>These representations carry increasingly less information about the original pixels of the image, but increasingly refined information about the class of the image. You can think of a convnet (or a deep network in general) as an information distillation pipeline.</p>
<h1 id="C2W1-Exploring-a-Larger-Dataset"><a href="#C2W1-Exploring-a-Larger-Dataset" class="headerlink" title="C2W1: Exploring a Larger Dataset"></a>C2W1: Exploring a Larger Dataset</h1><h2 id="Note-4"><a href="#Note-4" class="headerlink" title="Note"></a>Note</h2><ul>
<li>Data: <a href="https://www.kaggle.com/c/dogs-vs-cats" target="_blank" rel="noopener">https://www.kaggle.com/c/dogs-vs-cats</a></li>
<li><code>model.layers</code> API allows you to inspect the impact of convolutions on the images.</li>
</ul>
<h2 id="Code-4"><a href="#Code-4" class="headerlink" title="Code"></a>Code</h2><pre><code class="lang-python">import numpy as np
import random
from   tensorflow.keras.preprocessing.image import img_to_array, load_img

# Let&#39;s define a new Model that will take an image as input, and will output
# intermediate representations for all layers in the previous model after
# the first.
successive_outputs = [layer.output for layer in model.layers[1:]]

#visualization_model = Model(img_input, successive_outputs)
visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)

# Let&#39;s prepare a random input image of a cat or dog from the training set.
cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]
dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]

img_path = random.choice(cat_img_files + dog_img_files)
img = load_img(img_path, target_size=(150, 150))  # this is a PIL image

x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)
x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)

# Rescale by 1/255
x /= 255.0

# Let&#39;s run our image through our network, thus obtaining all
# intermediate representations for this image.
successive_feature_maps = visualization_model.predict(x)

# These are the names of the layers, so can have them as part of our plot
layer_names = [layer.name for layer in model.layers]

# -----------------------------------------------------------------------
# Now let&#39;s display our representations
# -----------------------------------------------------------------------
for layer_name, feature_map in zip(layer_names, successive_feature_maps):

  if len(feature_map.shape) == 4:

    #-------------------------------------------
    # Just do this for the conv / maxpool layers, not the fully-connected layers
    #-------------------------------------------
    n_features = feature_map.shape[-1]  # number of features in the feature map
    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)

    # We will tile our images in this matrix
    display_grid = np.zeros((size, size * n_features))

    #-------------------------------------------------
    # Postprocess the feature to be visually palatable
    #-------------------------------------------------
    for i in range(n_features):
      x  = feature_map[0, :, :, i]
      x -= x.mean()
      x /= x.std ()
      x *=  64
      x += 128
      x  = np.clip(x, 0, 255).astype(&#39;uint8&#39;)
      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid

    #-----------------
    # Display the grid
    #-----------------

    scale = 20. / n_features
    plt.figure( figsize=(scale * n_features, scale) )
    plt.title ( layer_name )
    plt.grid  ( False )
    plt.imshow( display_grid, aspect=&#39;auto&#39;, cmap=&#39;viridis&#39; )
</code></pre>
<h1 id="C2W2-Augmentation-A-technique-to-avoid-overfitting"><a href="#C2W2-Augmentation-A-technique-to-avoid-overfitting" class="headerlink" title="C2W2: Augmentation: A technique to avoid overfitting"></a>C2W2: Augmentation: A technique to avoid overfitting</h1><h2 id="Note-5"><a href="#Note-5" class="headerlink" title="Note"></a>Note</h2><h3 id="Image-augmentation"><a href="#Image-augmentation" class="headerlink" title="Image augmentation"></a>Image augmentation</h3><ul>
<li><p>Image augmentation implementation in Keras: <a href="https://keras.io/preprocessing/image/" target="_blank" rel="noopener">https://keras.io/preprocessing/image/</a></p>
</li>
<li><p>Image generator library lets you load the images into memory, process the images and then steam that to the training set to the neural network we will ultimatedly learn on.The preprocessing doesn’t require you to edit your raw images, nor does it amend them for you on-disk. It does it in-memory as it’s performing the training, allowing you to experiment without impacting your dataset.</p>
</li>
<li><p>As we start training, we’ll initially see that the accuracy is lower than with the non-augmented version. This is because of the random effects of the different image processing that’s being done. As it runs for a few more epochs, you’ll see the accuracy slowly climbing.</p>
</li>
<li><p>The image augmentation introduces a random element to the training images but if the validation set doesn’t have the same randomness, then its results can fluctuate. You don’t just need a broad set of images for training, you also need them for testing or the image augmentation won’t help you very much.(which does NOT mean that you should augment your validation set, see below)</p>
</li>
<li><p>Validation dataset should not be augmented: the validation set is used to estimate how your method works on real world data, thus it should only contain real world data. Adding augmented data will not improve the accuracy of the validation. It will at best say something about how well your method responds to the data augmentation, and at worst ruin the validation results and interpretability. As the validation accuracy is no longer a good proxy for the accuracy on new unseen data if you augment the validation data</p>
</li>
</ul>
<h2 id="Code-5"><a href="#Code-5" class="headerlink" title="Code"></a>Code</h2><pre><code class="lang-python">train_datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode=&#39;nearest&#39;)
</code></pre>
<h1 id="C2W3-Transfer-Learning"><a href="#C2W3-Transfer-Learning" class="headerlink" title="C2W3: Transfer Learning"></a>C2W3: Transfer Learning</h1><h2 id="Note-6"><a href="#Note-6" class="headerlink" title="Note"></a>Note</h2><h3 id="What-is-transfer-learning"><a href="#What-is-transfer-learning" class="headerlink" title="What is transfer learning"></a>What is transfer learning</h3><p>You can take an existing model, freeze many of its layers to prevent them being retrained, and effectively ‘remember’ the convolutions it was trained on to fit images, then added your own DNN underneath this so that you could retrain on your images using the convolutions from the other model.</p>
<h3 id="Why-dropout-can-do-the-regularization"><a href="#Why-dropout-can-do-the-regularization" class="headerlink" title="Why dropout can do the regularization"></a>Why dropout can do the regularization</h3><p>The idea behind Dropouts is that they remove a random number of neurons in your neural network. This works very well for two reasons: </p>
<ul>
<li><p>The first is that neighboring neurons often end up with similar weights, which can lead to overfitting, so dropping some out at random can remove this. </p>
</li>
<li><p>The second is that often a neuron can over-weigh the input from a neuron in the previous layer, and can over specialize as a result. It can not rely on any of the input which will be randomly dropped, instead, it will spread the weights, by which the weights will be shrinked.</p>
</li>
</ul>
<h2 id="Code-6"><a href="#Code-6" class="headerlink" title="Code"></a>Code</h2><pre><code class="lang-python">from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras.optimizers import RMSprop

from tensorflow.keras.applications.inception_v3 import InceptionV3

local_weights_file = &#39;/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5&#39;

pre_trained_model = InceptionV3(input_shape = (150, 150, 3), 
                                include_top = False,  # whether to include the fully-connected layer at the top of the network.
                                weights = None) # one of None (random initialization) or &#39;imagenet&#39; (pre-training on ImageNet).

for layer in pre_trained_model.layers:
  layer.trainable = False

last_layer = pre_trained_model.get_layer(&#39;mixed7&#39;)
last_output = last_layer.output

# Flatten the output layer to 1 dimension
x = layers.Flatten()(last_output)
# Add a fully connected layer with 1,024 hidden units and ReLU activation
x = layers.Dense(1024, activation=&#39;relu&#39;)(x)
# Add a dropout rate of 0.2
x = layers.Dropout(0.2)(x)                  
# Add a final sigmoid layer for classification
x = layers.Dense  (1, activation=&#39;sigmoid&#39;)(x)           

model = Model( pre_trained_model.input, x) 

model.compile(optimizer = RMSprop(lr=0.0001), 
              loss = &#39;binary_crossentropy&#39;, 
              metrics = [&#39;acc&#39;])
</code></pre>
<h1 id="C2W4-Multiclass-Classification"><a href="#C2W4-Multiclass-Classification" class="headerlink" title="C2W4: Multiclass Classification"></a>C2W4: Multiclass Classification</h1><h2 id="Note-7"><a href="#Note-7" class="headerlink" title="Note"></a>Note</h2><ul>
<li>Use CGI to generate images for Rock, Paper, Scissors</li>
</ul>
<h2 id="Code-7"><a href="#Code-7" class="headerlink" title="Code"></a>Code</h2><pre><code class="lang-python">train_generator = training_datagen.flow_from_directory(
    TRAINING_DIR,
    target_size=(150,150),
    class_mode=&#39;categorical&#39;
)

# Same for validation

model = tf.keras.models.Sequential([
    # Convolution layers
    # ...
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation=&#39;relu&#39;),
    # 3 nodes with softmax
    tf.keras.layers.Dense(3, activation=&#39;softmax&#39;) 
])
</code></pre>
<p>Another way of using <code>fit_generator</code> API via <code>(images, labels)</code>, instead of via directory</p>
<pre><code class="lang-python">history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size=32),
                              steps_per_epoch=len(training_images) / 32,
                              epochs=15,
                              validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),
                              validation_steps=len(testing_images) / 32)
</code></pre>

      
    </div>

    
      


    

    
    
    

    

    
      
    
    

    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Hao Ren</li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    
    <a href="http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/" title="Tensorflow Specialization Learning Note">http://invkrh.me/2019/03/11/tensorflow-specialization-learning-note/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Coding/" rel="tag"># Coding</a>
          
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/23/suan-xiang-feng-mi-ji/" rel="next" title="蒜香蜂蜜鸡">
                <i class="fa fa-chevron-left"></i> 蒜香蜂蜜鸡
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/13/google-hash-code-2019/" rel="prev" title="Google Hash Code 2019">
                Google Hash Code 2019 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/avatar.jpeg" alt="Hao Ren">
            
              <p class="site-author-name" itemprop="name">Hao Ren</p>
              <div class="site-description motion-element" itemprop="description">Machine Learning Engineer @ Criteo</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/invkrh" title="GitHub &rarr; https://github.com/invkrh" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://twitter.com/invkrh" title="Twitter &rarr; https://twitter.com/invkrh" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:invkrh@gmail.com" title="E-Mail &rarr; mailto:invkrh@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          
             <div class="cc-license motion-element" itemprop="license">
              
              
                
              
              
              
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
             </div>
          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#C1W1-A-New-Programming-Paradigm"><span class="nav-text">C1W1: A New Programming Paradigm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#New-programming-paradigm"><span class="nav-text">New programming paradigm</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code"><span class="nav-text">Code</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-fit-a-line"><span class="nav-text">How to fit a line</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C1W2-Introduction-to-Computer-Vision"><span class="nav-text">C1W2: Introduction to Computer Vision</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-1"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-are-the-labels-numbers-instead-of-words"><span class="nav-text">Why are the labels numbers instead of words</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-cross-entropy-CE"><span class="nav-text">What is cross entropy (CE)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Difference-between-categorical-crossentropy-and-sparse-categorical-crossentropy"><span class="nav-text">Difference between categorical_crossentropy and sparse_categorical_crossentropy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-1"><span class="nav-text">Code</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C1W3-Enhancing-Vision-with-Convolutional-Neural-Networks"><span class="nav-text">C1W3: Enhancing Vision with Convolutional Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-2"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Convolution-Layer"><span class="nav-text">Convolution Layer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MaxPooling-Layer"><span class="nav-text">MaxPooling Layer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-CNN-works"><span class="nav-text">Why CNN works</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-2"><span class="nav-text">Code</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Model"><span class="nav-text">Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-compute-output-size"><span class="nav-text">How to compute output size</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Two-kinds-of-padding"><span class="nav-text">Two kinds of padding:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-compute-number-of-parameters"><span class="nav-text">How to compute number of parameters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visualizing-the-Convolutions-and-Pooling"><span class="nav-text">Visualizing the Convolutions and Pooling</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C1W4-Using-Real-world-Images"><span class="nav-text">C1W4: Using Real-world Images</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-3"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ImageGenerator"><span class="nav-text">ImageGenerator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mini-batch"><span class="nav-text">Mini-batch</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Why-mini-batch"><span class="nav-text">Why mini-batch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Optimization"><span class="nav-text">Optimization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-3"><span class="nav-text">Code</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-1"><span class="nav-text">Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ImageDataGenerator"><span class="nav-text">ImageDataGenerator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visualizing-Intermediate-Representations"><span class="nav-text">Visualizing Intermediate Representations</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C2W1-Exploring-a-Larger-Dataset"><span class="nav-text">C2W1: Exploring a Larger Dataset</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-4"><span class="nav-text">Note</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-4"><span class="nav-text">Code</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C2W2-Augmentation-A-technique-to-avoid-overfitting"><span class="nav-text">C2W2: Augmentation: A technique to avoid overfitting</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-5"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-augmentation"><span class="nav-text">Image augmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-5"><span class="nav-text">Code</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C2W3-Transfer-Learning"><span class="nav-text">C2W3: Transfer Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-6"><span class="nav-text">Note</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-transfer-learning"><span class="nav-text">What is transfer learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-dropout-can-do-the-regularization"><span class="nav-text">Why dropout can do the regularization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-6"><span class="nav-text">Code</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C2W4-Multiclass-Classification"><span class="nav-text">C2W4: Multiclass Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Note-7"><span class="nav-text">Note</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-7"><span class="nav-text">Code</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Ren</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a></div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>




  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  
  <script src="/js/js.cookie.js?v=7.1.0"></script>
  <script src="/js/scroll-cookie.js?v=7.1.0"></script>


  

  

  
  

<script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'b0099Q4UewRf4nzkmN8I6zel-9Nh9j0Va',
    appKey: 'rCvpPdqxlekB0SeNTll2QOuW',
    placeholder: 'void',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: 'en' || 'zh-cn'
  });
</script>




  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://www.gstatic.com/firebasejs/5.8.1/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/5.8.1/firebase-firestore.js"></script>
  <script src="https://www.gstatic.com/firebasejs/5.8.1/firebase-auth.js"></script>
  <script>
    (function () {
      function getCount(docRef) {
        return docRef.get().then(function (doc) {
          if (!doc.exists) {
            return 0;
          } else {
            return doc.data().count;
          }
        });
      }

      // TODO: use distributed counter
      function increaseCount(docRef, firstViewOnly) {
        return function (prevCount) {
          if (firstViewOnly && window.localStorage) {
            // increase view count if the article is viewed for the first time
            // increase view count in case the doc is removed
            if (!window.localStorage.getItem('Tensorflow Specialization Learning Note') || prevCount == 0) {
              docRef.set({ count: prevCount + 1 })
              .then(function() {
                localStorage.setItem('Tensorflow Specialization Learning Note', true);
              })
              .catch(function(error) {
                console.error("Error writing document: ", error);
              });
            }
          } else {
            docRef.set({ count: prevCount + 1 });
          }
        }
      }

      function appendCount2PostMeta(el) {
        return function (count) {
          $(el)
            .append(
              $('<span>')
                .addClass('post-visitors-count')
                .append(
                  $('<span>')
                    .addClass('post-meta-divider')
                    .text('|'))
                .append(
                  $('<span>')
                    .addClass('post-meta-item-icon')
                    .append(
                      $('<i>')
                      .addClass('fa fa-eye')))
                .append(
                  $('<span>')
                  .text('Views ' + count)));
        }
      }

      function countRead() {
        // See: https://hexo.io/docs/helpers.html
        if (true) { //is article page
          var docRef = articles.doc('Tensorflow Specialization Learning Note')
          getCount(docRef)
            .then(increaseCount(docRef, true))
            .then(function() { return getCount(docRef) })
            .then(appendCount2PostMeta($('.post-meta'))); // only one post-meta class for post page
        } else if (false) { //is index page
          var titles = []; //array to titles

          

          var promises = titles.map(function (title) {
            return articles.doc(title);
          }).map(function (docRef) {
            return getCount(docRef);
          })

          Promise.all(promises).then(function (counts) {
            var metas = $('.post-meta'); // all the post-meta classes for current index page
            counts.forEach(function (val, idx) {
              appendCount2PostMeta(metas[idx])(val);
            })
          })
        }
      }

      var config = {
        apiKey: 'AIzaSyAnKKcq1jkgXEtYqusGtdL8fF7rLRh8LXo',
        authDomain: 'yorozuya-51151.firebaseapp.com',
        projectId: 'yorozuya-51151'
      };

      firebase.initializeApp(config);

      var db = firebase.firestore();

      var articles = db.collection('articles');

      firebase.auth().signInAnonymously().catch(function(error) {
        // Handle Errors here.
        var errorCode = error.code;
        var errorMessage = error.message;
        console.log(errorCode);
        console.log(errorMessage);
      });

      /*
      Only anonymous user of authorized domain sign in.
      Incease the counter for signed anonymous users.
      ===>
      Only request from authorized domain can increase counter.
      */

      firebase.auth().onAuthStateChanged(function(user) {
        if (user) {
          // User is signed in.
          var isAnonymous = user.isAnonymous;
          var uid = user.uid;
          countRead();
        } else {
          // User is signed out.
          // ...
        }
      });
    })()
  </script>


  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  

  

  
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
  <script type="text/javascript" src="/js/prism.js"></script>
</body>
</html>
